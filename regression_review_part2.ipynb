{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Evaluating\" data-toc-modified-id=\"Evaluating-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Evaluating</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-does-it-mean-to-Evaluate-your-model?\" data-toc-modified-id=\"What-does-it-mean-to-Evaluate-your-model?-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><strong><font color=\"red\">What does it mean to Evaluate your model?</font></strong></a></span></li><li><span><a href=\"#So-What?\" data-toc-modified-id=\"So-What?-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span><strong><font color=\"orange\">So What?</font></strong></a></span></li><li><span><a href=\"#Now-What?\" data-toc-modified-id=\"Now-What?-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><strong><font color=\"green\">Now What?</font></strong></a></span></li></ul></li><li><span><a href=\"#Feature-Engineering,-Feature-Evaluation,-and-Feature-Selection\" data-toc-modified-id=\"Feature-Engineering,-Feature-Evaluation,-and-Feature-Selection-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Feature Engineering, Feature Evaluation, and Feature Selection</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-Feature-Engineering?\" data-toc-modified-id=\"What-is-Feature-Engineering?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><strong><font color=\"red\">What is Feature Engineering?</font></strong></a></span></li><li><span><a href=\"#So-What?\" data-toc-modified-id=\"So-What?-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span><strong><font color=\"orange\">So What?</font></strong></a></span></li><li><span><a href=\"#Now-What?\" data-toc-modified-id=\"Now-What?-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span><strong><font color=\"green\">Now What?</font></strong></a></span></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-a-Model?\" data-toc-modified-id=\"What-is-a-Model?-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><strong><font color=\"red\">What is a Model?</font></strong></a></span></li><li><span><a href=\"#So-What?\" data-toc-modified-id=\"So-What?-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span><strong><font color=\"orange\">So What?</font></strong></a></span></li><li><span><a href=\"#Now-What?\" data-toc-modified-id=\"Now-What?-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span><strong><font color=\"green\">Now What?</font></strong></a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from sklearn.metrics import mean_squared_error,r2_score,explained_variance_score\n",
    "\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import env\n",
    "import util\n",
    "from wrangle_zillow import wrangle_zillow\n",
    "import explore\n",
    "import split_scale\n",
    "import features_zillow\n",
    "import model_zillow\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating\n",
    "\n",
    "### **<font color=red>What does it mean to Evaluate your model?</font>**\n",
    "\n",
    "There is a noteworthy saying that *“All models are wrong but some of them are useful.”* Keeping that in mind, how do we know if our model is useful?!\n",
    "\n",
    ">**Evaluating a model** is when we use specific metrics to measure how well our model can predict our target variable, y, using our chosen feature(s), X.\n",
    "\n",
    ">**Important Terminology:**\n",
    "\n",
    "- **y:** The actual target value (y variable value)\n",
    "\n",
    "\n",
    "- **$\\hat{y}$ or yhat:** The predicted target value (predicted y variable value)\n",
    "\n",
    "\n",
    "- **$\\bar{y}$ or ybar:** The mean of all of the actual target values (mean of all y variable values). This is your Baseline prediction value. \n",
    "\n",
    "    <font color=purple>A Baseline prediction is when you predict that every target value will be equal to the mean of all of the target values or ybar.</font> \n",
    "    \n",
    ">What is the best I can predict without using a variable? **If your model can't beat your Baseline prediction, scrap that model!** *'If the mean or median of your target variable is a good predictor of your target variable, you don't need to model at all.' - Ryan Orsinger*\n",
    "\n",
    "\n",
    "- **Residuals:** A residual is the difference between each predicted value, yhat, and each actual value, y. So, when you talk about the residuals of your model, you are talking about the amount of error your model has. If your model had 0 residuals, it would mean that your model was predicting at 100%. (A model predicting at 100% should be a red flag, BTW.)\n",
    "\n",
    "______\n",
    "\n",
    "\n",
    ">**Metrics for evaluating models:**\n",
    "    \n",
    "    \n",
    "- **Sum of Squared Errors (SSE):** All of the residuals squared and added together.  ($\\hat{y}$ - y)$^2$ == (y - $\\hat{y}$)$^2$. **This metric is not good for comparing model performance on datasets with different numbers of observations, such as train and test.**\n",
    "    \n",
    "    \n",
    "- **Mean Squared Error (MSE):** The SSE divided by the number of observations. **This metric can be used to compare the performance of a model on datasets with different number of observations** because it is the mean.\n",
    "    \n",
    "    \n",
    "- **Root Mean Squared Error (RMSE):** The square root of the MSE makes the measurement more meaningful because **it puts the value back in the original units of the target variable.** Along with MSE, **this metric can be used to compare the performance of a model on datasets with different numbers of observations**, such as train and test.\n",
    "\n",
    "    **<font color=purple>Evaluating whether RMSE is sufficiently small or not will depend on how accurate we need our model to be for our given application. There is no one answer for all data in general.</font>**\n",
    "    \n",
    "    \n",
    "- **$R^2$ or Explained Variance (score ranges from 0 to 1):** This tells you how much of the change in your y variable can be explained by your X variables. (Coefficient of Determination == Pearson's R squared) Only used in linear models. **For Example:** If $R^2$ = 0.43 for your regression equation, then it means that 43% of the variability in y is explained by the variable(s) in X.\n",
    "\n",
    ">A high $R^2$ score means that X is a valuable predictor for your y value. *(The significance of this score depends on your p-value.)*\n",
    "\n",
    ">A low $R^2$ means that your X is not a valuable predictor for you y value. *(The significance of this score depends on your p-value.)*\n",
    "    \n",
    "    \n",
    "- **F-regression test (p-value):** It compares a model with no predictors to the model that you specify. The metric it returns, p-value, tells you whether your $R^2$ score is significant. \n",
    "\n",
    "    **<font color=purple>What is the probability the RMSE of our trained model on this set of observations would be this small by random chance?</font>**\n",
    "\n",
    "### **<font color=orange>So What?</font>**\n",
    "\n",
    ">**Does the model add value?**\n",
    "\n",
    "- Does it perform better than if I made a random guess at my target value?\n",
    "\n",
    "\n",
    "- Does it perform better than if I predicted the average value of the y value every time?\n",
    "\n",
    "\n",
    "- Does it perform better than any existing model I have?\n",
    "\n",
    "\n",
    "- How much confidence should I have in this model?\n",
    "\n",
    "\n",
    "### **<font color=green>Now What?</font>**\n",
    "\n",
    ">**Define X and y variables**\n",
    "\n",
    "`X = df[[independent variable(s)]]`\n",
    "\n",
    "`y = df[[dependent variable]]`\n",
    "\n",
    ">**Create a Baseline**\n",
    "\n",
    "**- Use the mean or median of the target variable as every baseline_yhat value.**\n",
    "\n",
    "`baseline_yhat = y.mean()`\n",
    "\n",
    "OR\n",
    "\n",
    "`baseline_yhat = y.median()`\n",
    "\n",
    ">**Create a Model (for example - an ols model predicting home_value using bedrooms, bathrooms, and square_feet as features)**\n",
    "\n",
    "**- Import ols**\n",
    "\n",
    "`from statsmodels.formula.api import ols`\n",
    "\n",
    "**- Create Model**\n",
    "\n",
    "`ols_model = ols(formula='home_value ~ bedrooms + bathrooms + square_feet', data=train).fit()`\n",
    "\n",
    "**- Predict on Model**\n",
    "\n",
    "`ols_yhat = ols_model.predict(X_train)`\n",
    "\n",
    "\n",
    ">**Evaluate Your Model against your Baseline Using RMSE**\n",
    "\n",
    "**- Create a Handy DataFrame for Evaluating Your Models or Model and Baseline Value**\n",
    "\n",
    "`ols_eval = y_train.copy()`\n",
    "\n",
    "`ols_eval.rename(columns={'home_value': 'actual'}, inplace=True)`\n",
    "\n",
    "**- Add Baseline Value Column**\n",
    "\n",
    "`ols_eval['baseline_yhat'] = ols_eval['actual'].mean()`\n",
    "\n",
    "**- Add ols Predictions Column**\n",
    "\n",
    "`ols_eval['ols_yhat'] = ols_model.predict(X_train)`\n",
    "\n",
    "**- Calculate and Add Residuals Column for Plotting**\n",
    "\n",
    "`ols_eval['residuals'] = ols_eval.ols_yhat - ols_eval.actual`\n",
    "\n",
    "**- Compute the RMSE for our ols Model and Baseline Using Your Handy DataFrame**\n",
    "\n",
    "`from sklearn.metrics import mean_squared_error`\n",
    "`from math import sqrt`\n",
    "\n",
    "`baseline_RMSE = sqrt(mean_squared_error(ols_eval.actual, ols_eval.baseline_yhat))`\n",
    "\n",
    "`ols_RMSE = sqrt(mean_squared_error(ols_eval.actual, ols_eval.ols_yhat))`\n",
    "\n",
    "`print(f'My model has value: {ols_RMSE < baseline_RMSE}')`\n",
    "\n",
    "**- Compute the RMSE for the Model we created (You can also find these in the ols model summary below)**\n",
    "\n",
    "`ols_r2 = round(ols_model.rsquared,3)`\n",
    "\n",
    "`ols_p_value = ols_model.f_pvalue`\n",
    "\n",
    "`print(f'My R-squared score is significant: {ols_p_value < .05}')`\n",
    "\n",
    "**<font color=purple>If the RMSE for your ols model is smaller than the RMSE for your Baseline, and your p-value is less than your alpha, your model has value.</font>**\n",
    "\n",
    "OR\n",
    "\n",
    "**- Look at the R-squared and Prob (F-statistic) values in the summary chart**\n",
    "\n",
    "`ols_model.summary()`\n",
    "\n",
    ">**Visualize Residuals**\n",
    "\n",
    "**- Quick look at distribution of residuals**\n",
    "\n",
    "`plt.hist(np.log(ols_eval.residuals))`\n",
    "\n",
    "**- Look for Patterns in Actual vs Residuals**\n",
    "\n",
    "`plt.scatter(ols_eval.actual, ols_eval.residuals)`\n",
    "\n",
    "**- Look at Predictions vs Residuals**\n",
    "\n",
    "`plt.scatter(ols_eval.ols_yhat, ols_eval.residuals)`\n",
    "\n",
    ">**If Your First Model Beats Your Baseline, Try to Beat your First Model**\n",
    "\n",
    "**- Use the RMSE metric to compare the performance of successive models you build.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering, Feature Evaluation, and Feature Selection\n",
    "\n",
    "### **<font color=red>What is Feature Engineering?</font>**\n",
    "\n",
    "**Feature Engineering** is when you construct a new feature or column in your dataset using data from other columns in your dataset. You might decide to combine or separate the data from other columns to create new features for use in a machine learning algorithm. **Domain knowledge and qualitative research can be great guides in this area.**\n",
    "\n",
    "**Feature Evaluation** is an algorithmic way to measure the impact of a feature on a target variable.\n",
    "\n",
    "### **<font color=orange>So What?</font>**\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\"The features you use influence more than everything else the result. No algorithm alone, to my knowledge, can supplement the information gain given by correct feature engineering.\" <b>- Luca Massaron</b>\n",
    "</div>\n",
    "\n",
    "\n",
    "You might want to engineer new features to:\n",
    "\n",
    "- prepare the proper input dataset to be compatible with your machine learning algorithm's requirements.\n",
    "\n",
    "\n",
    "- improve the performance of your machine learning model.\n",
    "\n",
    "### **<font color=green>Now What?</font>**\n",
    "\n",
    "**SelectKBest - Feature Selection**\n",
    "\n",
    "- Select K Best is a filter method that uses a statistical test to gauge usefulness of features and keep those with the highest correlation to the target variable and remove those that are highly correlated with each other.\n",
    "\n",
    ">**Create the KBest Object**\n",
    "\n",
    "k = number_of_features\n",
    "\n",
    "`kbest = SelectKBest(f_regression, k=k)`\n",
    "\n",
    ">**Fit the KBest Object to Your train and test Data**\n",
    "\n",
    "`kbest.fit(X_train, y_train)`\n",
    "\n",
    ">**Use the KBest Object to Return SelectKBest Features**\n",
    "\n",
    "`best_features = X_train.columns[kbest.get_support()]`\n",
    "\n",
    ">**Use the KBest Object to Transform Your X_train Dataset if You Like**\n",
    "\n",
    "`X_reduced = kbest.transform(X_train)`\n",
    "\n",
    "____\n",
    "\n",
    "**RFE - Recursive Feature Elimination**\n",
    "\n",
    "- Recursive Feature Elimination is a wrapper method that takes in a ML algorithm and uses its performance to decide which features in your dataframe should be removed to achieve the best model evaluation.\n",
    "\n",
    "k = number_of_features\n",
    "\n",
    ">**Create the Linear Regression Object**\n",
    "\n",
    "`lm = LinearRegression()`\n",
    "\n",
    ">**Initialize the RFE Object**\n",
    "\n",
    "`rfe = RFE(lm, k)`\n",
    "\n",
    ">**Fit the RFE Object**\n",
    "\n",
    "`rfe.fit(X_train, y_train)`\n",
    "\n",
    ">**Get a List of Your Best Features**\n",
    "\n",
    "`X_train.columns[rfe.support_]`\n",
    "\n",
    ">**Transform your X_train if You Like**\n",
    "\n",
    "`X_rfe = rfe.transform(X_train)`\n",
    "\n",
    ">**Get the Rankings of Your Features**\n",
    "\n",
    "`rfe.ranking_`\n",
    "\n",
    "\n",
    "**Check out this super cool article showing [Feature Engineering](https://medium.com/@whitcrrd/linear-regression-part-ii-eda-feature-engineering-e66ea8763538) in a Linear Regression project! Some pretty cool ideas here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "### **<font color=red>What is a Model?</font>**\n",
    "\n",
    "\n",
    "\n",
    "### **<font color=orange>So What?</font>**\n",
    "\n",
    "\n",
    "\n",
    "### **<font color=green>Now What?</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
