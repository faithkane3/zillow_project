{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from sklearn.metrics import mean_squared_error,r2_score,explained_variance_score\n",
    "\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import env\n",
    "import util\n",
    "from wrangle_zillow import wrangle_zillow\n",
    "import explore\n",
    "import split_scale\n",
    "import features_zillow\n",
    "import model_zillow\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Notes and Practice\n",
    "\n",
    "- Regression is a supervised machine learning technique.\n",
    "\n",
    "\n",
    "- Linear Regression is used to model relationships between one or more independent variables and a continuous target dependent variable.\n",
    "\n",
    "\n",
    "- Our goal is to find the line of best fit, or in other words, the equation (y-intercept and coefficients(s)) that minimizes the errors between your actual (y) and predicted (yhat) target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "1       16.99  1.01  Female     No  Sun  Dinner     2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_scale.split_my_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 7) (74, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['size']]\n",
    "X_test = test[['size']]\n",
    "y_train = train[['tip']]\n",
    "y_test = test[['tip']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the LR Object using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm1 = LinearRegression()\n",
    "lm1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit/Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return the intercept and coefficients created by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept:  [1.3281486]\n",
      "coefficients:  [[0.62602051]]\n"
     ]
    }
   ],
   "source": [
    "lm1_y_intercept = lm1.intercept_\n",
    "print('intercept: ', lm1_y_intercept)\n",
    "lm1_coefficients = lm1.coef_\n",
    "print('coefficients: ', lm1_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = lm1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.58018962],\n",
       "       [2.58018962],\n",
       "       [2.58018962],\n",
       "       [2.58018962],\n",
       "       [3.83223065]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns a numpy array\n",
    "\n",
    "yhat[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Sklearn LinearRegression Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model Evaluation Metrics:\n",
      "Mean Squared Error: 1.22\n",
      "\n",
      "r2_score: 20.51%\n",
      "\n",
      "This means that 20.51% of the variance in the value of tips can be explained by the size of the party.\n"
     ]
    }
   ],
   "source": [
    "mse_lm1 = mean_squared_error(y_train, yhat)\n",
    "print(f\"Linear Model Evaluation Metrics:\\nMean Squared Error: {mse_lm1:.3}\") \n",
    "print()\n",
    "r2_lm1 = r2_score(y_train, yhat)\n",
    "print(f\"r2_score: {r2_lm1:.2%}\")\n",
    "print()\n",
    "print(f\"This means that {r2_lm1:.2%} of the variance in the value of tips can be explained by the size of the party.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 =  0.20513559210842236\n",
      "r2 =  0.20513559210842236\n"
     ]
    }
   ],
   "source": [
    "# This is another way to return the r-squared of our model\n",
    "\n",
    "print('r2 = ', lm1.score(X_train, y_train))  # feeding in X_train, y_train\n",
    "print('r2 = ', r2_score(y_train, yhat))      # feeding in y_train, yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Check out the Residuals\n",
    "\n",
    "- A residual is a measure of how far away a point is vertically from the regression line. It is the error between a predicted value and the observed actual value.\n",
    "\n",
    "\n",
    "- A typical Residual Plot has the residual values on the Y-axis and the independent variable on the x_axis. \n",
    "\n",
    "\n",
    "- The most important assumption of a linear regression model is that the errors are independent and normally distributed. So, what does a good Residual Plot look like?\n",
    "\n",
    "    - It has a high density of points close to the origin and low density of points away from the origin.\n",
    "    \n",
    "    - It is symmetric about the origin.\n",
    "    \n",
    "    - If we project all of the residuals onto the y_axis, we should have a normally distributed curve.\n",
    "    \n",
    "    - We should not see any patterns in the residuals as we move along the x-axis.\n",
    "    \n",
    "\n",
    "- If we do not see the characteristics above, it means we have not completely captured the predictive information of the data in our model.\n",
    "\n",
    "\n",
    "- Finding patterns in our residuals may mean that there is a non-linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the OLS Model and Print out Evaluation Summary\n",
    "\n",
    "- OLS stands for Ordinary Least Squares, and the method 'Least Squares' means that we're trying to fit a regression line that would minimize the square of distance from the regression line.\n",
    "\n",
    "\n",
    "- The r-squared value returned here is .205 which means that about 21% of the variance in tip values is explained by the size of the parties at the restaurant.\n",
    "\n",
    "\n",
    "- Our r-squared value here is pretty right on with our Linear Regression model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>tip</td>       <th>  R-squared:         </th> <td>   0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   43.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 23 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>5.60e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:22:53</td>     <th>  Log-Likelihood:    </th> <td> -258.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   170</td>      <th>  AIC:               </th> <td>   520.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   168</td>      <th>  BIC:               </th> <td>   526.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.3281</td> <td>    0.253</td> <td>    5.249</td> <td> 0.000</td> <td>    0.829</td> <td>    1.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>size</th>      <td>    0.6260</td> <td>    0.095</td> <td>    6.585</td> <td> 0.000</td> <td>    0.438</td> <td>    0.814</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.508</td> <th>  Durbin-Watson:     </th> <td>   1.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  15.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.742</td> <th>  Prob(JB):          </th> <td>0.000352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.212</td> <th>  Cond. No.          </th> <td>    8.91</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    tip   R-squared:                       0.205\n",
       "Model:                            OLS   Adj. R-squared:                  0.200\n",
       "Method:                 Least Squares   F-statistic:                     43.36\n",
       "Date:                Mon, 23 Mar 2020   Prob (F-statistic):           5.60e-10\n",
       "Time:                        15:22:53   Log-Likelihood:                -258.07\n",
       "No. Observations:                 170   AIC:                             520.1\n",
       "Df Residuals:                     168   BIC:                             526.4\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.3281      0.253      5.249      0.000       0.829       1.828\n",
       "size           0.6260      0.095      6.585      0.000       0.438       0.814\n",
       "==============================================================================\n",
       "Omnibus:                       14.508   Durbin-Watson:                   1.931\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               15.903\n",
       "Skew:                           0.742   Prob(JB):                     0.000352\n",
       "Kurtosis:                       3.212   Cond. No.                         8.91\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ols_model = ols('y ~ x', data=df).fit()\n",
    "# ols_yhat = ols_model.predict(x)\n",
    "\n",
    "tips_model = ols('tip ~ size', data=train).fit()\n",
    "tips_yhat = tips_model.predict(X_train)\n",
    "\n",
    "tips_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
